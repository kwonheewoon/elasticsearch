* 기본 상황 파악
    1. _cat/health를 통해 클러스터의 red, yellow 상태 돌입 여부와 미할당 샤드의 수,
    현재 클러스터에 합류된 것으로 판단되는 노드의 수를 확인
    2. _cat/nodes를 통해 어떤 노드가 클러슽에서 빠졌는지 마스터 노드가 제대로 선출되어 있는지 파악, 평균 부하, 힙 사용량, 메모리 사용량, CPU 사용량을 확인
        그다음 디스크 사용량을 확인 각 노드에서 직접 df를 통해 확인하거나 GET _nodes/stats의 fs 항목에서 확인한다.

        GET _cat/health?format=json // 클러스터 전체 상태 확인

        GET _cat/nodes?format=json // 노드별 자원 상태 확인
        GET _nodes/stats // 노드별 자세한 상태 확인 디스크 할당, 인덱스, 샤드 수 등

        GET _cat/indices?v&s=store.size:desc // 인덱스 사이즈 오름차순 정렬

        GET _cluster/allocation/explain?pretty // 클러스터 할당 설명 api


* 샤드 할당 비활성화
    GET _cat/health나 GET _cat/nodes의 수행 결과, 클러스터에 합류된 노드의 수가 원래 있어야 할 노드의 수보다 적은 것이 확인되면 일단 그 상황에서
    바로 샤드 할당을 끄는것이 중요

    노드 하나가 클러스터에서 빠지면 그 노드가 들고 있던 샤드의 수만큼 복제본 샤드의 수도 줄어든다. 그러면 엘라스틱서치는 인덱스 설정에 지정된 number_of_replicas
    를 맞추기 위해 새 복제본 샤드를 할당하고 데이터를 복사하는 작업을 수행한다. 장애 상황은 클러스터으 부하가 높은 상황이 많다.
    노드가 빠져서 평소보다 적은 수의 노드가 트래픽을 처리해야 하는데 복제본 샤드 할당과 데이터 복사 작업으로 부하가 가중되면 한계에 다다른 다른 노드가 문제를 일으키며
    클러스터에서 빠질 수 있다 이러면 다시 복제본 샤드의 수가 줄어들고 추가 복제본 샤드 할당이 일어난다. 이런 동작이 연쇄적인 장애를 일으키며 클러스터 전체가
    걷자블 수 없는 상황으로 치닫을 수 있다.

    샤드 할당을 비활성화할 때는 none과 primaries, new_primaries 중 하나를 선택해야 한다. 장애 처리 도중 주 샤드의 할당을 허용해야 한다면
    primaries나 new_primaries를 선택한다. 그러한 부하를 허용하기 어려운 좀 더 심각한 상황에서는 none를 선택한다.
    primaries로 지정하는 것이 좀 더 범용적이다. 이후 주요 조치가 끝나고 샤드 할당 작업을 재개해야 할 때 다시 all로 바꾸면 된다.


* 클라이언트의 트래픽 차단
    샤드 할당을 비활성화한 뒤에는 클라이언트의 트래픽을 차단하는 것이 좋다. 이는 클러스터 리소스를 장애 상황 복구에 집중할 수 있게 해 준다.
    또한 클라이언트로부터 무거운 검색이나 집계 요청이 인입되어 장애가 발생한 것이라면 이런 트래픽의 추가 인입을 막는것이 중요하다.
    추가 색인 작업을 차단하는 것도 크게 주요하다. 노드 재시작 등의 조치를 했다면 샤드 복구 과정이 이어진다. 만약 그 사이에 샤드에 변경이
    있었다면 엘라스틱서치는 해당 작업을 전파해서 재처리하는 과정을 수행한다. 장애 상황에서 이런 작업이 많다면 전체 샤드 복구 시간이 늦어지고
    클러스터가 추가 부하를 받는다. 따라서 클라이언트의 트래픽을 차단하는 것이 좋다.

    이럴 때를 위해 클러스터 구성 시 처음부터 조정 전용 노드를 앞에 두는 것이 좋다. 서버 자원에 여유가 있다면 읽기 작업을 담당하는 조정전용 노드와 쓰기 작업을
    담당하는 조정 전용 노드를 분리하는 전략도 선택할 만하다. 조정 전용 노드의 재시작은 부담이 없으므로 장애 발생 시 상황을 봐서 조정 전용 노드를 내려버리면 된다.

* 로그 확인과 대응 조치
    급히 샤드 할당 비활성화와 클라이언트 트래픽 차단을 끝냈다면 본격적인 장애 대응 조치에 돌입해야 한다.
    어떤 조치를 수행할지 결정하기 위해서는 장애 원인이나 현상 파악이 필요하다. 지금까지 확인된 증상과 정보를 통해 어떤 로그를 봐야 하는지 결정하고
    로그를 확인한다. 이후 확인된 장애 원인이나 증상에 맞춰 필요한 조치를 결정하고 수행한다. 일반적으로는 클러스터에서 제외된 노드나 STW가 예상되는 노드의
    서버 로그를 먼저 확인한다.

    기본 상황 파악 단계에서 GET _cat/health, GET _cat/nodes를 수행했을 때 HTTP 연결 자체가 되지 않는다면 해당 요청을 받는 노드에 엘라스틱서치
    프로세스가 제대로 올라와 있는지 ps 명령어와 서버 로그를 통해 확인한다. 프로세스가 내려가 있다면 서버 로그를 확인해서 프로세스를 올려도 되는 상황인지
    확인하고 프로세스를 올린다.

    응답은 오지만 마스터 노드가 선출되지 않아 동작을 수행하지 않는 경우에는 마스터 후보 역할 노드의 서버 로그와 프로세스 기동 상태를 확인하고 선출 실패의
    원엔에 맞는 조치를 수행해야 한다.

    GET _cat/health 요청에는 응답이 금방 돌아오지만 GET _cat/nodes 요청에는 응답이 돌아오지 않고 오랜 시간 지체되다 타임아웃이 떨어진다면
    일부 노드가 STW 상태로 응답하지 않는 먹통 상태가 됐을 가능성을 의심해야한다. 이럴 때는 노드 재기동을 고려해야 한다. STW가 예상되는 노드의
    서버 로그와 GC 로그를 확인하고 kill 명령어로 프로세스를 죽인 뒤 재기동할지 결정한다.

    STW 상황이 심각해서 노드를 재기동하기로 결정했다면 바로 Kill -15를 수행한다. 정상적이고 준비된 상황에서 수행하는 의도적인 롤링 리스타트와는 달리
    사전에 flush를 수행하지 않는다. kill -15 수행 이후에는 ps를 통해 프로세스가 제대로 죽었는지 확인해야 한다. kill -15에도 프로세스가 잘 죽지 않는다면 바로
    kill -9를 결단하는 것이 일반적으로 더 좋다.

    장애 상황에 따라 문제 노드의 재기동 이후 샤드 할당을 다시 켜서 green으로 돌아오는 것을 기다린 후 다른 문제 노드를 재기동할지 아니면 샤드 할당을 꺼둔
    채로 여러 노드를 각각 재기동할지도 선택해야 한다. 후자를 선택한다면 클러스터 상태가 일시적으로 red 까지 떨어지는 리스크를 감수해야 한다. 그러나
    연쇄적인 STW으로 여러 노드가 죽는 속도가 너무 빠르다면 위험한 노드를 빨리 Kill 시키는 것이 나은 선택일 수 있다. red가 되는 리스크를 감수하려면
    서비스의 트래픽을 잃지 않도록 사전에 설계가 잘 되어 있어야 한다.

    GET _cat/health와 GET _cat/nodes의 반응이 모두 빠른데 클러스터에 합류하지 못한 노드가 있다면 해당 노드의 서버 로그와 프로세스 기동 상태를 확인한다.
    단순히 oom으로 죽은 것뿐이라면 노드를 재기동하면 된다. 하드웨어 문제로 인해 프로세스가 죽었다면 노드를 재기동하지 않는 편이 좋다. 하드웨어 점검 및 조치가 완료된 이후에 재기동한다.







*

    GET _cluster/allocation/explain?pretty // 클러스터 할당 설명 api
    이 API는 미할당 샤드의 할당을 더 이상 진행하지 않는 이유를 설명한다. 응답의 unassigned_info 부분과 node_allocation_decisions 부분을 살펴보면
    어떤 문제가 있었는지 파악한다. node_allocation_decisions 부분은 각 노드별로 이 샤드를 할당해서 가져갈지를 결정할때 어떤 사유로 할당하지 않기로 했는지를 설명