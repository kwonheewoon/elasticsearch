*집계 기본
    집계 쿼리에서 size를 0으로 지정하면 검색에 상위 매칭된 문서가 무엇인지 받아볼 수 없다
    하지만 이와 상관없이 검색 조건에 매치되는 모든 문서는 집계 작업에 사용된다 핵심은 집계 연산의 결과이지 검색 쿼리에 매치된 문서 내용이 아니기 때문
    size를 0으로 지저하면 각 샤드에서 수행한 검색 결과에서 상위 문서의 내용을 수집해 모을 필요가 없고 점수를 계산하는 과정도 수행하지 않음

* 메트릭 집계
    메트릭 집계는 문서에 대한 산술적인 연산을 수행
    * avg, max, min, sum
    GET kibana_sample_data_ecommerce/_search
    {
      "size": 0,
      "query": {
        "term": {
          "currency": {
            "value": "EUR"
          }
        }
      },
      "aggs": {
        "my-avg-aggregation-name": {
          "avg": { // max,min ...
            "field": "taxless_total_price"
          }
        }
      }
    }

    * stats
        - 지정한 필드의 평균, 최댓값, 최솟값, 합, 개수를 모두 계산
        GET kibana_sample_data_ecommerce/_search
        {
          "size": 0,
          "query": {
            "term": {
              "currency": {
                "value": "EUR"
              }
            }
          },
          "aggs": {
            "my-stats-aggregation-name": {
              "stats": {
                "field": "taxless_total_price"
              }
            }
          }
        }
        // response
        "aggregations": {
            "my-stats-aggregation-name": {
              "count": 4675,
              "min": 6.98828125,
              "max": 2250,
              "avg": 75.05542864304813,
              "sum": 350884.12890625
            }
          }

    * cardinality 집계
        - 지정한 필드가 가진 교유한 값의 개수를 계산 후 반환
        GET kibana_sample_data_ecommerce/_search
        {
          "size": 0,
          "query": {
            "term": {
              "currency": {
                "value": "EUR"
              }
            }
          },
          "aggs": {
            "my-cardinality-aggregation-name": {
              "cardinality": {
                "field": "customer_id",
                "precision_threshold": 3000
              }
            }
          }
        }
        // precision_threshold 정확도를 조절하기 위한 옵션
        precision_threshold가 최종 cardinality보다 높으면 충분 cardinality 값이 precision_threshold를 넘으면 정확도는 떨어짐

* 버킷 집계
    문서를 특정 기준으로 쪼개어 여러 부분 집합으로 나눈다 이 부분 집합을 버킷이라고 한다
    버킷에 포함된 문서를 대상으로 별도의 하위 집계를 수행할 수 있다

    GET kibana_sample_data_flights/_search
    {
      "size": 0,
      "query": {
        "match_all": {}
      },
      "aggs": {
        "distance-kilometers-range": {
          "range": {
            "field": "DistanceKilometers",
            "ranges": [
              {
                "to": 5000
              },
              {
                "from": 5000,
                "to": 10000
              },
              {
                "from": 10000
              }
            ]
          },
          "aggs": {
            "average-ticket-price": {
              "avg": {
                "field": "AvgTicketPrice"
              }
            }
          }
        }
      }
    }
    // range 밑에 집계 함수 agg가 포함 ranges에 기술된 버킷별 하위 집계를 수행하는 용도

    * date_range 집계
        - 집계 쿼리는 각 샤드에 요청이 들어오면 ES는 해당 요청을 캐시에 올린다 이후 동일한 집계 요청이 오면 캐시에 저장된 집계 결괏값을
        반환하는데 now가 포함된 집계 요청은 캐시되지 않는다 호출시점에 따라 내용이 달라지기 때문에

    GET kibana_sample_data_ecommerce/_search
    {
      "size": 0,
      "query": {
        "term": {
          "currency": {
            "value": "EUR"
          }
        }
      },
      "aggs": {
        "data-range-aggs": {
          "date_range": {
            "field": "order_date",
            "ranges": [
              {
                "to": "now-10d/d"
              },
              {
                "from": "now-10d/d",
                "to" : "now"
              },
              {
                "from": "now"
              }
            ]
          }
        }
      }
    }

    * histogram 집계(숫자형 타입 한정)
        지정한 필드의 값을 기준으로 버킷을 나눈다는 점에서 range 집계와 유사하다 다른 점은 버킷 구분의 경계 기준값을 직접 지정하는 것이 아니라
        버킷의 간격을 지정해서 경계를 나눈다는 점이다

        GET kibana_sample_data_flights/_search
        {
          "size": 0,
          "query": {
            "match_all": {}
          },
          "aggs": {
            "my-histogram": {
              "histogram": {
                "field": "DistanceKilometers",
                "interval": 1000, // 버킷을 나눌 구간
                "offset": 50, // 시작 위치
                "min_doc_count": 300 // 집계된 문서의 최소 개수 만족하지 않으면 해당 버킷은 제외
              }
            }
          }
        }

    * date_histogram 집계(날짜형 타입 한정)
        GET kibana_sample_data_ecommerce/_search
        {
          "size": 0,
          "query": {
            "match_all": {}
          },
          "aggs": {
            "my-date-histogram": {
              "date_histogram": {
                "field": "order_date",
                "calendar_interval" : "day" // 날짜별로 버킷을 나눔 minute, hour, day, month, quarter, year 필드 지정 가능
              }
            }
          }
        }
        - "fixed_interval" : ms, s, m, h, d 단위로 사용 가능
        - "offset" : "+6h" utc 기준 06시 부터 시작하는 버킷 구성


    * terms 집계
        - 지정한 필드에 대해 가장 빈도수가 높은 term 순서대로 버킷을 생성 버킷을 최대 몇 개까지 생성할 것인지를 size로 지정
            ㄴ terms 집계는 각 샤드에서 size 개수만큼 term을 뽑아 빈도수를 센다 각 샤드에서 수행된 계산을 한 곳으로 모아
            합산한 후 size 개수만큼 버킷을 뽑는다 그러므로 size 개수와 각 문서의 분포에 따라 그 결과가 정확하지 않을 수 있다
        GET kibana_sample_data_logs/_search
        {
          "size": 0,
          "query": {
            "match_all": {}
          },
          "aggs": {
            "my-terms-aggs": {
              "terms": {
                "field": "host.keyword", // 필드명 뒤에 .keyword는 서브 필드로 host 필드는 멀티 필드이다 text, keyword 필드로 구성
                "size": 10
              }
            }
          }
        }
        // response
        "aggregations": {
            "my-terms-aggs": {
              "doc_count_error_upper_bound": 0, // doc_count의 오차 상한선 이 값이 크다면 size를 높이는 것을 고려
              "sum_other_doc_count": 0, // 최종적으로 버킷에 포함되지 않은 문서 수를 나타낸다 상위 term에 들지 못한 문서 개수의 총합
              "buckets": [
                {
                  "key": "artifacts.elastic.co",
                  "doc_count": 6488
                },
                {
                  "key": "www.elastic.co",
                  "doc_count": 4779
                },
                {
                  "key": "cdn.elastic-elastic-elastic.org",
                  "doc_count": 2255
                },
                {
                  "key": "elastic-elastic-elastic.org",
                  "doc_count": 552
                }
              ]
            }
          }


    * composite 집계
        composite 집계는 sources로 지정된 하위 집계의 버킷 전부를 페이지네이션을 이용해서 효율적으로 순회하는 집계다
        또한 sources에 하위 집계를 여러 개 지정한 뒤 조합된 버킷을 생성 가능

        composite 아래의 size는 페이지네이션 한 번에 몇 개의 버킷을 반환할 것인가를 지정
        sources에는 버킷을 조합하여 순회할 하위 집계를 지정
        하위 집계 가능 구문(terms 집계, histogram 집계, date_histogram 집계)

        composite 하위 집계의 terms 집계에는 size를 지정하지 않음 composite 집계 자체가 버킷 전체를 순차적으로 방문하는 목적의 집계이기 때문에
        terms 집계의 size 개념이 필요없다
        GET kibana_sample_data_logs/_search
        {
          "size": 0,
          "query": {
            "match_all": {}
          },
          "aggs": {
            "composite-aggs": {
              "composite": {
                "size": 1000,
                "sources": [
                  {
                    "terms-aggs": {
                      "terms": {
                        "field": "host.keyword"
                      }
                    }
                  },
                  {
                    "date-histogram-aggs" : {
                      "date_histogram": {
                        "field": "@timestamp",
                        "calendar_interval": "day"
                      }
                    }
                  }
                ],
                "after": { // 이 필드의 값 이후의 시점부터 버킷을 집계하겠다는 옵션
                  "terms-aggs" : "cdn.elastic-elastic-elastic.org",
                  "date-histogram-aggs" : 1675209600000
                }
              }
            }
          }
        }

* 파이프라인 집계
    파이프라인 집계는 문서나 필드의 내용이 아니라 다른 집계 결과를 집계 대상으로 한다 즉 다른 집계의 결과를 입력값으로 가져와
    작업을 수행한다 주로 buckets_path라는 인자를 통해 다른 집계의 결과를 가져오며, 이 buckets_path는 상대 경로로 지정한다
    다음은 buckets_path를 지정할 때 사용할 수 있는 대표적인 구문이다

    - >: 하위 집계로 이동하는 구분자
    - .: 하위 메트릭으로 이동하는 구분자
    - 집계 이름
    - 메트릭 이름

    또한 buckets_path에서는 > 또는 . 문자를 통해 하위 경로로 이동할 수 있으나 상위 경로로는 이동할 수 없다.

    - cumulative_sum 집계
        cumulative_sum 집계는 다른 집계의 값을 누적하여 합산한다
        buckets_path로 누적 합산할 집계의 이름을 지정한다

    GET kibana_sample_data_ecommerce/_search
    {
      "size": 0,
      "query": {
        "match_all": {}
      },
      "aggs": {
        "daily-timestamp-bucket": {
          "date_histogram": {
            "field": "order_date",
            "calendar_interval": "day"
          },
          "aggs": {
            "daily-total-quantity-average": {
              "avg": {
                "field": "total_quantity"
              }
            },
            "pipeline-sum" : {
              "cumulative_sum": {
                "buckets_path": "daily-total-quantity-average"
              }
            }
          }
        }
      }
    }

    일 단위로 total_quantity의 평균을 구하기 위해 date_histogram으로 버킷을 나눈 뒤 그 하위 집계로 avg 집계를 지정했다 그리고 date_histogram
    의 하위 집계로 cumulative_sum 집계를 추가 지정했다. cumulative_sum의 buckets_path에서는 누적 합산을 수행할 집계로 daily-total-quantity-average를
    지정 이렇게 지저하면 cumulative_sum을 수행할 때마다 daily-total-quantity-average를 찾아 그 합을 누적 합산한다
    pipline-sum에서 누적 합산 결과를 확인 가능

    * max_bucket 집계
    max_bucket은 다른 집계의 결과를 받아서 그 결과가 가장 큰 버킷의 key와 결괏값을 구하는 집계다

    GET kibana_sample_data_ecommerce/_search
    {
      "size": 0,
      "query": {
        "match_all": {}
      },
      "aggs": {
        "daily-timestamp-bucket": {
          "date_histogram": {
            "field": "order_date",
            "calendar_interval": "day"
          },
          "aggs": {
            "daily-total-quantity-average": {
              "avg": {
                "field": "total_quantity"
              }
            }
          }
        },
        "max-total-average": {
          "max_bucket": {
            "buckets_path": "daily-timestamp-bucket>daily-total-quantity-average"
          }
        }
      }
    }

    요청을 자세히 보면 buckets_path 부분에 avg 집계의 이름인 daily-total-quantity-average가 아니라
    daily-timestamp-bucket>daily-total-quantity-average를 지정했다 앞서 cumulative_sum에서는
    daily-total-quantity-average만을 지정했었다 값을 끌어올 집계 이름으 바로 명시하지 않은 이유는
    buckets_path가 절대 경로가 아닌 상대경로를 사용하기 때문이다
    현재 max_bucket 집계가 위치한 계층에서는 daily-total-quantity-average를 인식할 수 없다
    따라서 daily-timestamp-bucket>daily-total-quantity-average 형식으로 한 단계씩 경로를 지정해야 의도한 대로 동작

