* 인덱스의 샤드 개수(number_of_shards)는 한 번 지정하면 reindex 등의 특별한 작업을 수행하지 않는 한 변경할 수 없다.
그런데 샤드 개수를 어떻게 지정하느냐에 따라 엘라스틱서치의 클러스터 전체의 성능이 크게 달라진다.

* 샤드의 크기와 개수 조정
    클러스터에 샤드 숫자가 너무 많아지면 클러스터 성능이 눈에 띄게 떨어진다.
    샤드 하나당 루씬 인덱스가 하나씩 더 뜨며 힙을 차지한다. 주 샤드를 하나 더 띄울 때마다 복제본 샤드도 늘어나는 것을
    고려하면 무작정 number_of_shards를 늘릴 수는 없다. 그렇다고 샤드 숫자를 적게 지정하면 샤드 하나당 크기가 커진다.
    샤드 하나의 크기가 너무 커지는 것도 심각한 문제다. 샤드의 크기가 지나치게 크면 재기동이나 장애 상황등에서 샤드 복구,
    복제본 샤드 생성에 너무 많은 시간이 소요된다.
    이렇게 되면 문제 상황에서 클러스터 안정성이 크게 떨어진다. 장애로 인해 재기동한 노드가 샤드 복구를 하는 과정 자체가 너무 무거워서
    복구 도중 다시 죽는 일도 생길 수 있다. 전체적인 서비스의 성능도 쉽게 체감될 정도로 감소한다.

    중요 원칙은 샤드 하나의 크기를 일정 기준 이하로 유지해야 한다는 것이다.
    전체 샤드의 수를 체크하는 것은 그다음이다. 샤드의 크기를 기준 크기 이하로 유지하는 선에서 전체 샤드 개수를 최대한 줄이는 방향으로 접근해야 한다.
    ES 공식 블로그에선 햐드 하나당 20~40GB 크기가 적절하다고 소개하는데 실제 운영 경함상 샤드 하나당 크기가 20GB만 되어도 다양한 상황에서
    꽤 느리고 무겁다. 20~40GB 샤드도 어느정도 버틸만 하지만 수 GB 내외 수준에서 조정하는 것이 좋다.

    GET _cat/shards?v&s=store:desc // 샤드 크기 확인

    힙 1GB당 20개 이하의 샤드를 들고있는 것이 적절하다고 설명한다.
    약 32GB 힙 기준으로는 노드당 640 샤드 이하다.

    // 샤드 개수 확인
    GET _cat/health?v
    GET _cat/allocation?v


* 샤딩
    엘라스틱서치의 샤드는 이름 자체가 의미하듯 샤딩, 즉 분산처리를 위해 생긴 개념이다.
    전체 샤드 개수를 줄이는 것만 생각하다 보면 분산처리의 강점을 충분히 살리지 못할 수도 있다.
    특정 인덱스 주 샤드와 복제본 샤드가 모든 노드에 고르게 퍼지도록 설정하는 것도 중요한 요소다.
    노드 대수가 n대라면 number_of_shards를 n의 배수로 지정해 모든 노드가 작업을 고르게 분산받도록 설정하는 방법 등이 사용된다.
    특히 서비스 중요도가 높은 인덱스나 성능을 타이트하게 조정해야 하는 인덱스라면 이 부분을 싱경써야 한다.

    물론 반드시 그렇게 지정할 필요는 없는데. 서비스상 빈번하게 호출되지 않는 인덱스나 크기가 너무 작은 인덱스의 샤드를 모든 노드에 배치시킬 필요는 없다.
    n의 배수에도 크게 집착하지 않아도 된다. 어차피 추후 선형적 확장을 위해 추가 서버가 투입되면 이 숫자가 달라지게 된다. 또한 한 엘라스틱서치 클러스터
    에서 활발하게 작업중인 인덱스의 수가 이미 충분히 많다면 단일 인덱스에 대해 모든 노드가 일을 하고 있는지를 과도하게 신경 쓸 필요가 없을 수도 있다.
    한 인덱스의 작업에 참여하지 않는 노드이더라도 다른 인덱스의 작업에 리소스를 사용할 것이기 때문이다. 서비스 중요도와 함께 샤드의 크기, 개수 등의
    요소를 함께 적절히 고려한 중용이 필요하다.

* 롤링 리스타트
    엘라스틱서치 운영 중에는 롤링 리스타트를 수행할 일이 매우 많다. 동적으로 변경할 수 없는 설정의 적용, 플러그인 설치나 삭제의 적용,
    엘라스틱서치의 버전 업그레이드 등 다양한 상황에서 롤링 리스타트가 필요하다. 그리고 무엇보다 장애 상황에서 문제를 일으키고 있는 노드를 재기동
    하기 위해 많이 수행된다.

    롤링 리스타트는 크게 샤드 할당 비활성화, flush 수행, 노드 재기동, 샤드 할당 활성화, green 상태까지 대기 순으로 수행된다.

    - 샤드 할당 비활성화
        노드를 재기동하기 위해 엘라스틱서치 프로세스를 종료시키면 클러스터 구성에서 노드가 빠진다.
        빠진 노드가 데이터 노드라면 주 샤드를 새로 지정하고 줄어든 복제본 개수를 맞추기 위해 복제본 샤드를 새로 할당해 생성하는 작업이 수행된다.
        사실 롤링 리스타트 과정에서는 복제본 샤드를 새로 생성하는 작업이 필요없다. 재기동한 노드가 클러스터에 합류하면 자신이 들고 있던 샤드를
        복제본 샤드로 다시 띄우기 때문이다. 하지만 클러스터 입장에서는 노드가 재기동을 위해 빠졌는지 장애로 인해 빠졌는지 구분할 방법이 없다.
        그저 노드가 빠지면 일정 시간 대기한 뒤 복제본 샤드 할당 작업을 수행할 뿐이다.

        불필요한 작업을 막기위해 엘라스틱 클러스터의 샤드 할당 작업을 제어할 수 있다.
        클러스터 설정 API를 통해 cluster.routing.allocation.enable 설정을 동적으로 변경하면 된다.

        PUT _cluster/settings
        {
            "transient" : {
                "cluster.routing.allocation.enable" : "primaries"
            }
        }

        primaries는 주 샤드만 할당을 허용하는 설정
        all : 모든 종류의 샤드 할당을 허용, 가장 기본적인 상태이며 작업 중이나 장애 상황이 아니면 이 상태여야 한다.
            재기동이 끝나면 샤드 할당을 다시 활성화하는 과정이 있다. 이때 all로 지정하게 된다.
        new_primaries : 새로 생성된 인덱스의 주 샤드 할당만을 허용
        none: 모든 샤드 할당을 불허한다. 이렇게 주 샤드의 할당도 불허하면 새로 인덱스가 생기는 상황 등 특정한 타이밍에 일부 인덱스의 일부 데이터가
            서비스 되지 않는 상황이 발생할 수 있다.

    - flush
        flush를 수행해서 translog를 비우고 데이터를 디스크에 안전하게 기록한다. 루씬 인덱스에 반영되지 않고
        아직 translog에 남아 있는 내용은 노드 재기동시 샤드 복구 과정에서 처리되기 때문에 이 작업은 반드시 필요한 작업은 아니다.
        하지만 이런 작업에는 시간과 자원이 소요된다. 미리 flush를 수행하고 재기동을 하는 것이 좋다.

        POST _flush

        POST _flush/synced 엘라스틱서치 7.6 미만의 구버전에서는 flush가 아니라 synced flush를 수행

        synced flush는 flush를 수행한 이후에 샤드에 sync_id라는 마커를 발급한다. 재기동 이후 샤드 복구과정에서
        sync_id를 비교해서 더 이상 샤드에 새로운 색인 작업이 들어오지 않았는지 확인한다. sync_id가 같은 샤드는 내용이 같은 샤드로 파악한다.

        최신 버전에서는 이런 방법을 사용하지 않는다. 샤드 이력 보존이라는 메커니즘을 사용하기 때문에 flush만 수행해도 같은 효과가 난다.
        synced flush는 지원 중단 선언되었으며 8 버전부터는 삭제되었다.

    - 노드 재기동
        샤드 할당을 비활성화하고 flush를 무사히 완료했으면 노드를 재기동한다. 프로세스를 kill하고 새로 띄우면 된다.
        프로세스를 새로 띄우기 전에 반드시 기존 프로세스가 완전히 종료됐는지 확인하고 띄워야 한다.

        이후 노드가 완전히 기동하고 클러스터에 합류할 때까지 대기한다. 다음과 같이 cat nodes API를 호출해서 재기동한 노드가 클러스터에
        잘 붙었는지 확인한다.

        GET _cat/nodes

        클러스터의 상태가 좋지 않거나 장애 상황에서 재기동을 수행 중이라면 cat nodex API의 수행에 오랜 시간이 걸릴 수 있다.
        cat nodes API의 수행 자체가 클러스터에 부담을 줄 수도 있다. 이런 상황이라면 직접 엘라스틱서치의 로그를 보며 노드가 잘
        기동했는지 확인한다. 로그에서 started가 확인되면 일단 노드가 기동은 된 것이다.

        노드 기동을 확인했으면 클러스터에 잘 합류됐는지 확인해야 한다.
        위 로그의 전후에서 이후 마스터 누드와 관련된 로그를 찾는다. 마스터 노드를 잘 찾았는지, 마스터 노드 찾기에 실패했는지, 혹은
        해당 노드가 마스터 노드로 선출됐는지 등을 로그에서 확인한다.

    - 샤드 할당 활성화
        노드 재기동에 성공했으면 샤드 할당을 다시 활성화 한다.

        PUT _cluster/settings
        {
            "transient" : {
                "cluster.routing.allocation.enable" : "all"
            }
        }

    - green 상태까지 대기
        이후 클러스터 상태가 green이 될 때까지 대기한다.
        GET _cat/health?v